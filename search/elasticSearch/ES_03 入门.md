# 部署

官网地址：https://www.elastic.co/guide/en/elasticsearch/reference/7.9/index.html

## es 部署

详见 docker 下的 es 安装教程

## 中文分词

```shell
elasticsearch-plugin  install \
https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.9.3/elasticsearch-analysis-ik-7.9.3.zip
```

### 设置

- 通过 `mapping` 映射来选择哪些字段使用ik分词

- 通过 `POST analyze` 可以指定分词器获取分词结果

  ```shell
  curl -x POST /_analyze -d
  {
      "analyzer": "ik_smart",
      "text": "铝合金营养不粘微压锅6L" 
  }
  
  # RESTFUL 格式
  POST /_analyze?pretty=true
  {
    "analyzer": "ik_smart",
    "text": "铝合金营养不粘微压锅6L" 
  }
  ```

### 自定义词库

```shell
cd <es_dir>/analysis-ik/
create my.dic
vim <es_dir>/analysis-ik/IKAnalyzer.cfg.xml
```

## 配置

### 配置文件的位置

- 使用归档安装方式，默认配置文件目录在`config`文件夹内
- 可以通过设置环境变量`ES_PATH_CONF=/path/to/my/config`来自定义配置目录:
  - `elasticsearch.yml` ES的配置文件
  - `jvm.options` ES jvm 配置
  - `log4j2.properties` 日志配置

### 常用配置

```yml
# 集群名称，只有同样的集群名称的节点，才能构建集群，默认 elasticsearch
cluster.name: my-es
cluster.initial_master_nodes: ["node1"] # 初始master节点，集群初始化时用来引导

node.name: node1 # 当前节点的名称

path.data: /path/to/es/data # 数据的存放路径
path.logs: /path/to/es/log  # 日志的存放路径

# 哪些ip可以访问，默认 _local_
# _local_  127.0.0.1
# _site_   内网可访问
# _global_ 全局可访问
network.host: _site_ 

http.port: 9200 # REST端口，默认9200

transport.port: 9300     # 节点间内部通信端口
transport.compress: true # 启用节点间压缩，默认false

# 集群ips
discovery.zen.ping.unicast.hosts: 
    - "192.168.0.1"
    - "192.168.0.2:9300"
    - "my.els.com"
# 最小主节点数，为了防止 脑裂 集群节点数最少为 半数+1
# 节点集群最好大于3个，2个有可能会脑裂。。。
discovery.zen.minimum_master_nodes: 2 

```

### 启动异常及修复

- `max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]`

```shell
    vim /etc/security/limits.conf
    * soft nofile 65536
    * hard nofile 65536

    # 保存后重新登录用户
    # 使用 ulimit -S -n/ulimit -H -n 查看是否生效

```

- `max number of threads [1024] for user [elasticsearch] is too low, increase to at least [4096]`

```shell
    vim /etc/security/limits.d/90-nproc.conf
    *          soft    nproc     4096
```

- `max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]`

```shell
vim /etc/sysctl.conf
    vm.max_map_count=262144 
    sysctl -p
```

- `system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk`

  ```shell
      # 这是在因为Centos6不支持SecComp，
      # 而ES5.2.0默认bootstrap.system_call_filter为true进行检测，
      # 所以导致检测失败，失败后直接导致ES不能启动
      # 解决：
      # 在elasticsearch.yml中配置bootstrap.system_call_filter为false
      # 注意要在Memory下面:
  
      bootstrap.memory_lock: false
      bootstrap.system_call_filter: false
  ```

# 基本概念

## 集群

可以将多台ES服务器作为集群使用，可以在任何一台节点上进行搜索。集群有一个默认的名称（可修改），“elasticsearch”，这个集群名称必须是唯一的，因为集群的节点是通过集群名称来加入集群的。

确保在相同环境中不要有相同的集群名称，否则有可能节点会加入到非预期的集群中。

## 节点

- 节点是作为集群的一部分的单个服务器，存储数据，并且参与集群的索引和搜索功能。
- 与集群一样，节点由一个名称标识，默认情况下，该名称是在启动时分配给节点的随机通用唯一标识符（UUID）
- 如果不希望使用默认值，则可以定义所需的任何节点名称。此名称对于管理目的很重要，因为您希望确定网络中的哪些服务器对应于ElasticSearch集群中的哪些节点。

## 分片 和副本(shard)

- 索引可能存储大量数据，这些数据可能会超出单个节点的硬件限制。例如，占用1TB磁盘空间的10亿个文档的单个索引可能不适合单个节点的磁盘，或者速度太慢，无法单独满足单个节点的搜索请求。
- 为了解决这个问题，ElasticSearch提供了将索引细分为多个片段（称为碎片）的能力。创建索引时，只需定义所需的碎片数量。每个分片（shard）本身就是一个完全功能性和独立的“索引”，可以托管在集群中的任何节点上。

### 为什么要分片?

- 它允许水平拆分/缩放内容量
- 它允许跨碎片（可能在多个节点上）分布和并行操作，从而提高性能/吞吐量

如何分配分片以及如何将其文档聚合回搜索请求的机制完全由ElasticSearch管理，并且对用户是透明的。

在随时可能发生故障的网络/云环境中，非常有用，强烈建议在碎片/节点以某种方式脱机或因任何原因消失时使用故障转移机制。为此，ElasticSearch允许将索引分片的一个或多个副本复制成所谓的副本分片，简称为副本分片。

### 为什么要有副本？

- 当分片/节点发生故障时提供高可用性。因此，需要注意的是，副本分片永远不会分配到复制它的原始/主分片所在的节点上。
- 允许您扩展搜索量/吞吐量，因为可以在所有副本上并行执行搜索。

总而言之，每个索引可以分割成多个分片。索引也可以零次（意味着没有副本）或多次复制。复制后，每个索引将具有主分片（从中复制的原始分片）和副本分片（主分片的副本）。

- 可以在创建索引时为每个索引定义分片和副本的数量。
- 创建索引后，还可以随时动态更改副本的数量。
- 可以使用收缩和拆分API更改现有索引的分片数量
- 建议在创建索引时就考虑好分片和副本的数量

默认情况下，ElasticSearch中的每个索引都分配一个主分片和一个副本，这意味着如果集群中至少有两个节点，则索引将有一个主分片和另一个副本分片（一个完整副本），每个索引总共有两个分片。

> 每个ElasticSearch分片都是一个Lucene索引。在一个Lucene索引中，可以有最多数量的文档。从Lucene-5843起，限制为2147483519（=integer.max_value-128）个文档。您可以使用 api监视碎片大小

## 索引(ndices)

### 索引基本概念

索引是具有某种相似特性的文档集合。例如，

- 拥有客户数据的索引
- 产品目录的的索引
- 订单数据的另的索引

索引由一个名称（必须全部是小写）标识，当对其中的文档执行索引、搜索、更新和删除操作时，该名称用于引用索引。

在单个集群中，您可以定义任意多个索引。

可以将索引暂且理解为 MySql中的 database。

###  索引类型(type)

- ~~一个索引可以有多个类型。~~例如一个索引下可以有文章类型，也可以有用户类型，也可以有评论类型。
- **在一个索引中不能再创建多个类型，在以后的版本中将删除类型的整个概念**。

一个索引对象可以存储多个不同用途的对象，通过索引类型可以区分单个索引中的不同对象，可以理解为关系型数据库中的表。每个索引类型可以有不同的结构，但是不同的索引类型不能为相同的属性设置不同的类型。

> 在Elasticsearch 7.0.0或更高版本中创建的索引不再接受 `_default_`映射。在6.x中创建的索引将继续像以前一样在Elasticsearch 6.x中运行。在7.0中的API中不推荐使用类型，对索引创建，放置映射，获取映射，放置模板，获取模板和获取字段映射API进行重大更改。



##  文档(document)

一个文档是一个可被索引的基础信息单元。比如:
- 拥有某一个客户的文档，
- 某一个产品的一个文档，
- 拥有某个订单的一个文档。

文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存在的互联网数据交互格式。

在一个index/type里面，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须被索引/赋予一个索引的type。

可以理解为关系型数据库中表的一行记录。每个文档由多个字段构成，ElasticSearch 是一个非结构化的数据库，每个文档可以有不同的字段，并且有一个唯一的标识符。

## 映射(mapping)

Mapping 非常类似于静态语言中的数据类型：声明一个变量为 int 类型的变量，以后这个变量都只能存储 int 类型的数据。同样的，一个 number 类型的 mapping 字段只能存储 number 类型的数据。

同语言的数据类型相比，Mapping 还有一些其他的含义，Mapping 不仅告诉 ElasticSearch 一个 Field 中是什么类型的值， 它还告诉 ElasticSearch 如何索引数据以及数据是否能被搜索到。

ElaticSearch 默认是动态创建索引和索引类型的 Mapping 的。这就相当于无需定义 Solr 中的 Schema，无需指定各个字段的索引规则就可以索引文件，很方便。但有时方便就代表着不灵活。比如，ElasticSearch 默认一个字段是要做分词的，但我们有时要搜索匹配整个字段却不行。如有统计工作要记录每个城市出现的次数。对于 name 字段，若记录 new york 文本，ElasticSearch 可能会把它拆分成 new 和 york 这两个词，分别计算这个两个单词的次数，而不是我们期望的 new york。

# 基本操作

## 查看基本状况

```shell
# 命令: curl -X GET "localhost:9200/_cat
# 返回值
=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/tasks
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/thread_pool/{thread_pools}
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
/_cat/nodeattrs
/_cat/repositories
/_cat/snapshots/{repository}
/_cat/templates
```

### 查看健康状态

`http://localhost:9200/_cat/health?v`

`GET /_cat/health?v`

- 说明：v是用来要求在结果中返回表头

状态说明

```shell
Green - everything is good (cluster is fully functional)，#即最佳状态
Yellow - all data is available but some replicas are not yet allocated (cluster is fully functional)，#即数据和集群可用，但是集群的备份有的是坏的
Red - some data is not available for whatever reason (cluster is partially functional)，#即数据和集群都不可用
```

### 查看集群节点

`http://localhost:9200/_cat/nodes?v`  

`GET /_cat/nodes?`

### 查看所有索引信息

`http://localhost:9200/_cat/indices?v` 

`GET /_cat/indices?v`

### 创建一个索引

```shell
# 创建一个名为 customer 的索引。pretty要求返回一个漂亮的json 结果
PUT /customer?pretty

PUT /customer?pretty=true
# 返回值
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "customer"
}
```

###  索引一个文档到customer索引中

```shell
curl -X PUT "localhost:9200/customer/_doc/1?pretty" -H 'Content-Type: application/json' -d'
{
  "name": "John Doe"
}
'

# 添加一个文档到索引中
PUT /customer/_doc/1?pretty
{
  "name": "John Doe"
}
```

###  从customer索引中获取指定id的文档

```shell
curl -X GET "localhost:9200/customer/_doc/1?pretty"

# 从指定索引中获取文档
GET /customer/_doc/1?pretty
{
  "_index" : "customer",
  "_type" : "_doc",
  "_id" : "1",
  "_version" : 1,
  "_seq_no" : 0,
  "_primary_term" : 1,
  "found" : true,
  "_source" : {
    "name" : "John Doe"
  }
}
```

###  查询所有文档

```shell
GET /customer/_search?q=*&sort=name:ASC&pretty
```

- JSON格式方式

```shell
GET /customer/_search
{
  "query": { "match_all": {} },
  "sort": [
    {"name": "asc" }
  ]
}
```

#  索引管理

![image-20201116195819535](ES_03 入门/image-20201116195819535.png)



## 概述

索引映射可以配置索引的文档字段类型以及全文索引的分词解析器等，调用映射接口会创建索引，所以重建索引需要删掉旧索引（这里暂不涉及到平滑重建索引）

### 映射索引

```shell
curl -x PUT /user -d
{
	"mappings": {
    	"properties": {
            // 普通字段
            "name": {
                "type": "text" // 字段类型下面会详细讲解
                "index": true, // 是否可检索，默认是
                
                // 仅text类型可用属性，text会被全文索引
                "analyzer": "ik_smart", // 建立索引时的分词器，默认default英文分词器
                "search_analyser": "ik_max_word" // 搜索时的分词器
                
                // 多元索引
                // 一个字段可以创建不同的索引，name既可以是text全文检索，也可以是keyword用来精准查询
                "fields: {
                    "raw": { // name.raw 即可使用这个字段
               	        "type": "keyword"
                        // 嵌套设置项 ...
                    }
                }
            },
            // 数组或对象
            "field2_array_or_object": {
            	"dynamic": false, 是否支持动态将新字段建立索引，默认false
                "properties": {
                    "field2.item1": {} // 同普通字段配置
                    // ...
                }
            }
        }
    }
}
```

### 常用映射字段类型

详细的字段文档可以看[这里](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/mapping-types.html)

- `keyword`关键字类型，一般用来存储id、状态、标签等不需要解析的值

  > 什么时候需要用关键字类型？
  >
  > - 不打算使用范围查询来搜索标识符数据
  > - 需要快速检索。关键词字段上的术语查询搜索通常比数字字段上的术语搜索快。
  > - 如果不确定使用方式，可以尝试使用多索引类型

- `text` 用于分析的文本类型，可以全文检索

  > analyzer 设置分词器，如 `ik_smart` `ik_max_word`，默认英文分词器

- `boolean` 布尔类型

- `numbers` 数字类型

  > 常用数字类型
  >
  > - long     => int64
  > - integer  => int32
  > - double   => float64
  > - float    => float32

- `date` 日期类型

```json
{
    "created": {
        "type": "date",
        // format 字段可以指定可解析的类型
        // 如下可解析 2020-11-11 10:23:34 和 时间戳
        // 只有格式化的日期支持1970年以前
        // epoch_seconds 支持精确到秒的时间戳
        "format": "yyyy-MM-dd HH:mm:ss||epoch_seconds",
    }
}
```

- `alias` 其他字段的别名

```json
{
    "field1": {
        "type": "long"
    },
    "field1_alias": {
        "type": "alias",
        "path": "field1"
    }
}
```

- `object` json对象类型

  > - 对象的索引类型，实际是对象的深层单个字段
  > - object如果字段过多可能会引起‘索引爆炸’，这时可以用`flattened`来索引整个对象

- `array` 数组类型

  > - 数组类型的所有元素都应该是同样的类型
  > - 数组元素支持对象
  > - 数组的搜索可能不是预期结果，可以参考[nested](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/nested.html)类型，优化数组搜索



## 创建索引

创建一个名为twitter的索引，设置索引的分片数为3，备份数为2。注意：在ES中创建一个索引类似于在数据库中建立一个数据库(ES6.0之后类似于创建一个表)

```shell
PUT /twitter
{
    "settings" : {
        "index" : {
            "number_of_shards" : 3,
            "number_of_replicas" : 2
        }
    }
}
# 简写
PUT /twitter
{
    "settings" : {
        "number_of_shards" : 3,
        "number_of_replicas" : 2
    }
}
```

说明：
默认的分片数是5到1024
默认的备份数是1
索引的名称必须是小写的，不可重名

## 创建mapping映射

在ES中创建一个mapping映射类似于在数据库中定义表结构，即表里面有哪些字段、字段是什么类型、字段的默认值等；也类似于solr里面的模式schema的定义

```shell
PUT /twitter?pretty
{
    "settings" : {
        "index" : {
            "number_of_shards" : 3,
            "number_of_replicas" : 2
        }
    },
   "mappings" : {
        "properties" : {
                "field1" : { "type" : "text" }
           }
    }
}
```



## 创建索引时定义别名

```shell
PUT /twitter?pretty
{
    "aliases" : {
        "alias_1" : {},
        "alias_2" : {
            "filter" : {
                "term" : {"user" : "kimchy" }
            },
            "routing" : "kimchy"
        }
    }
}
```

## 创建索引时返回的结果说明

![image-20201116201158333](ES_03 入门/image-20201116201158333.png)

## 查看索引定义

```shell
# GET Index
# GET /twitter，可以一次获取多个索引（以逗号间隔） 获取所有索引 _all 或 用通配符*
GET /twitter/_mapping
```

## 删除索引

`DELETE /twitter`

说明：

可以一次删除多个索引（以逗号间隔） 删除所有索引 _all 或 通配符 *

## 判断索引是否存在

`HEAD twitter`

HTTP status code 表示结果 404 不存在 ， 200 存在

## 修改索引的settings信息

索引的设置信息分为静态信息和动态信息两部分。静态信息不可更改，如索引的分片数。动态信息可以修改。

```shell
REST 访问端点：
/_settings 更新所有索引的。
{index}/_settings 更新一个或多个索引的settings。
```

- https://www.elastic.co/guide/en/elasticsearch/reference/current/index-modules.html#index-modules-settings

##  修改备份数

```shell
PUT /twitter/_settings
{
    "index" : {
        "number_of_replicas" : 2
    }
}
```

## 设置回默认值，用null

```shell
PUT /twitter/_settings
{
    "index" : {
        "refresh_interval" : null
    }
}
```

### 设置索引的读写

```shell
index.blocks.read_only：设为true,则索引以及索引的元数据只可读
index.blocks.read_only_allow_delete：设为true，只读时允许删除。
index.blocks.read：设为true，则不可读。
index.blocks.write：设为true，则不可写。
index.blocks.metadata：设为true，则索引元数据不可读写。
```

## 索引模板

在创建索引时，为每个索引写定义信息可能是一件繁琐的事情，ES提供了索引模板功能，让你可以定义一个索引模板，模板中定义好settings、mapping、以及一个模式定义来匹配创建的索引。

注意：模板只在索引创建时被参考，修改模板不会影响已创建的索引

### 新增/修改名为tempae_1的模板，匹配名称为te* 或 bar*的索引创建：

```shell
PUT _template/template_1
{
  "index_patterns": ["te*", "bar*"],
  "settings": {
    "number_of_shards": 1
  },
  "mappings": {
    "type1": {
      "_source": {
        "enabled": false
      },
      "properties": {
        "host_name": {
          "type": "keyword"
        },
        "created_at": {
          "type": "date",
          "format": "EEE MMM dd HH:mm:ss Z YYYY"
        }
      }
    }
  }
}
```

### 查看索引模板

```shell
GET /_template/template_1
GET /_template/temp* 
GET /_template/template_1,template_2
GET /_template
```

### 删除模板

```shell
DELETE /_template/template_1
```

##  Open/Close Index  打开/关闭索引

```shell
POST /my_index/_close
POST /my_index/_open
```

说明：

- 关闭的索引不能进行读写操作，几乎不占集群开销。
- 关闭的索引可以打开，打开走的是正常的恢复流程。

##  Shrink Index 收缩索引

索引的分片数是不可更改的，如要减少分片数可以通过收缩方式收缩为一个新的索引。新索引的分片数必须是原分片数的因子值，如原分片数是8，则新索引的分片数可以为4、2、1 。

### 什么时候需要收缩索引呢?

最初创建索引的时候分片数设置得太大，后面发现用不了那么多分片，这个时候就需要收缩了

###  收缩的流程

- 先把所有主分片都转移到一台主机上；
- 在这台主机上创建一个新索引，分片数较小，其他设置和原索引一致；
- 把原索引的所有分片，复制（或硬链接）到新索引的目录下；
- 对新索引进行打开操作恢复分片数据；
- (可选)重新把新索引的分片均衡到其他节点上。

### 收缩前的准备工作：

将原索引设置为只读；
将原索引各分片的一个副本重分配到同一个节点上，并且要是健康绿色状态。

```shell
PUT /my_source_index/_settings
{
  "settings": {
    <!-- 指定进行收缩的节点的名称 -->
    "index.routing.allocation.require._name": "shrink_node_name",
    <!-- 阻止写，只读 -->
     "index.blocks.write": true
  }
}
```

### 进行收缩

```shell
POST my_source_index/_shrink/my_target_index
{
  "settings": {
    "index.number_of_replicas": 1,
    "index.number_of_shards": 1,
    "index.codec": "best_compression"
  }}
```

### 监控收缩过程：

```shell
GET _cat/recovery?v
GET _cluster/health
```



## Split Index 拆分索引

当索引的分片容量过大时，可以通过拆分操作将索引拆分为一个倍数分片数的新索引。能拆分为几倍,由创建索引时指定的index.number_of_routing_shards 路由分片数决定。这个路由分片数决定了根据一致性hash路由文档到分片的散列空间。

如index.number_of_routing_shards = 30 ，指定的分片数是5，则可按如下倍数方式进行拆分：

```shell
5 → 10 → 30 (split by 2, then by 3)
5 → 15 → 30 (split by 3, then by 2)
5 → 30 (split by 6)
```

### 为什么需要拆分索引？

- 当最初设置的索引的分片数不够用时就需要拆分索引了，和压缩索引相反
- 注意：只有在创建时指定了index.number_of_routing_shards 的索引才可以进行拆分，ES7开始将不再有这个限制。
- 和solr的区别是，solr是对一个分片进行拆分，es中是整个索引进行拆分。

### 拆分步骤：

- 准备一个索引来做拆分：

   ```shell
  PUT my_source_index
  {
      "settings": {
          "index.number_of_shards" : 1,
          <!-- 创建时需要指定路由分片数 -->
          "index.number_of_routing_shards" : 2
      }
  }
  ```

- 先设置索引只读：

```shell
PUT /my_source_index/_settings
{
  "settings": {
    "index.blocks.write": true
  }
}
```

- 做拆分：

```shell
POST my_source_index/_split/my_target_index
{
  "settings": {
    <!--新索引的分片数需符合拆分规则-->
    "index.number_of_shards": 2
  }
}
```

- 监控拆分过程：

```shell
GET _cat/recovery?v
GET _cluster/health
```

## Rollover Index 别名滚动指向新创建的索引

对于有时效性的索引数据，如日志，过一定时间后，老的索引数据就没有用了。我们可以像数据库中根据时间创建表来存放不同时段的数据一样，在ES中也可用建多个索引的方式来分开存放不同时段的数据. 比数据库中更方便的是ES中可以通过别名滚动指向最新的索引的方式，让你通过别名来操作时总是操作的最新的索引。

ES的rollover index API 让我们可以根据满足指定的条件（时间、文档数量、索引大小）创建新的索引，并把别名滚动指向新的索引。

**注意：这时的别名只能是一个索引的别名。**

### Rollover Index 示例：

- 创建一个名字为logs-0000001 、别名为logs_write 的索引：

```shell
PUT /logs-000001
{
  "aliases": {
    "logs_write": {}
  }
}
```

- 添加1000个文档到索引logs-000001，然后设置别名滚动的条件

```shell
POST /logs_write/_rollover
{
  "conditions": {
    "max_age":   "7d",
    "max_docs":  1000,
    "max_size":  "5gb"
  }
}
```

- 说明：

  如果别名logs_write指向的索引是7天前（含）创建的或索引的文档数>=1000或索引的大小>= 5gb，则会创建一个新索引 logs-000002，并把别名logs_writer指向新创建的logs-000002索引

### Rollover Index 新建索引的命名规则：

- 如果索引的名称是-数字结尾，如logs-000001，则新建索引的名称也会是这个模式，数值增1
- 如果索引的名称不是-数值结尾，则在请求rollover api时需指定新索引的名称

```shell
POST /my_alias/_rollover/my_new_index_name
{
  "conditions": {
    "max_age":   "7d",
    "max_docs":  1000,
    "max_size": "5gb"
  }
}
```

### 在名称中使用Date math（时间表达式）

如果你希望生成的索引名称中带有日期，如logstash-2016.02.03-1 ，则可以在创建索引时采用时间表达式来命名：

```shell
# PUT /<logs-{now/d}-1> with URI encoding:
PUT /%3Clogs-%7Bnow%2Fd%7D-1%3E
{
  "aliases": {
    "logs_write": {}
  }
}
PUT logs_write/_doc/1
{
  "message": "a dummy log"
} 
POST logs_write/_refresh
# Wait for a day to pass
POST /logs_write/_rollover
{
  "conditions": {
    "max_docs":   "1"
  }
}
```

### Rollover时可对新的索引作定义：

 ```shell
PUT /logs-000001
{
  "aliases": {
    "logs_write": {}
  }
}
POST /logs_write/_rollover
{
  "conditions" : {
    "max_age": "7d",
    "max_docs": 1000,
    "max_size": "5gb"
  },
  "settings": {
    "index.number_of_shards": 2
  }
}
 ```

### Dry run  实际操作前先测试是否达到条件：

```shell
POST /logs_write/_rollover?dry_run
{
  "conditions" : {
    "max_age": "7d",
    "max_docs": 1000,
    "max_size": "5gb"
  }
}
```

说明：

测试不会创建索引，只是检测条件是否满足

注意：rollover是你请求它才会进行操作，并不是自动在后台进行的。你可以周期性地去请求它。

##  索引监控

### 查看索引状态信息

- 官网addr:https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-stats.html

### 查看所有的索引状态：

```shell
GET /_stats
```

### 查看指定索引的状态信息：

```shell
GET /index1,index2/_stats
```

### 查看索引段信息

- 官网链接：https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-segments.html

```shell
GET /test/_segments 
GET /index1,index2/_segments
GET /_segments
```

### 查看索引恢复信息

官网链接：
https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-recovery.html

```shell
GET index1,index2/_recovery?human
GET /_recovery?human
```

### 查看索引分片的存储信息

官网链接：

https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-shards-stores.html

```shell
# return information of only index test
GET /test/_shard_stores
# return information of only test1 and test2 indices
GET /test1,test2/_shard_stores
# return information of all indices
GET /_shard_stores  
GET /_shard_stores?status=green
```

##  索引状态管理

### Clear Cache 清理缓存

```shell
POST /twitter/_cache/clear
```

默认会清理所有缓存，可指定清理query, fielddata or request 缓存

```shell
POST /kimchy,elasticsearch/_cache/clear
POST /_cache/clear
```

### Refresh，重新打开读取索引

```shell
POST /kimchy,elasticsearch/_refresh
POST /_refresh
```

### Flush，将缓存在内存中的索引数据刷新到持久存储中

```shell
POST /twitter/_flush
```

### Force merge 强制段合并

```shell
POST /kimchy/_forcemerge?only_expunge_deletes=false&max_num_segments=100&flush=true
```

可选参数说明：

- max_num_segments 合并为几个段，默认1
- only_expunge_deletes 是否只合并含有删除文档的段，默认false
- flush 合并后是否刷新，默认true

```shell
POST /kimchy,elasticsearch/_forcemerge
POST /_forcemerge
```

#  映射详解

##  Mapping 映射是什么

映射定义索引中有什么字段、字段的类型等结构信息。相当于数据库中表结构定义，或 solr中的schema。因为lucene索引文档时需要知道该如何来索引存储文档的字段。
ES中支持手动定义映射，动态映射两种方式。

### 为索引创建mapping

```shell
PUT test
{
<!--映射定义 -->
"mappings" : {
<!--名为type1的映射类别 mapping type-->
        "type1" : {
        <!-- 字段定义 -->
            "properties" : {
            <!-- 名为field1的字段，它的field datatype 为 text -->
                "field1" : { "type" : "text" }
            }
        }
    }
}
```

 说明：映射定义后续可以修改

### 映射类别 Mapping type 废除说明

ES最先的设计是用索引类比关系型数据库的数据库，用mapping type 来类比表，一个索引中可以包含多个映射类别。这个类别存在一个严重的问题，就是当多个mapping type中存在同名字段时（特别是同名字段还是不同类型的），在一个索引中不好处理，因为搜索引擎中只有 索引-文档的结构，不同映射类别的数据都是一个一个的文档（只是包含的字段不一样而已）

**从6.0.0开始限定仅包含一个映射类别定义（ "index.mapping.single_type": true ），兼容5.x中的多映射类别。从7.0开始将移除映射类别。**

**为了与未来的规划匹配，请现在将这个唯一的映射类别名定义为“_doc”,因为索引的请求地址将规范为：`PUT {index}/_doc/{id} and POST {index}/_doc`**

Mapping 映射示例：

```shell
PUT twitter
{
  "mappings": {
    "_doc": {
      "properties": {
        "type": { "type": "keyword" },
        "name": { "type": "text" },
        "user_name": { "type": "keyword" },
        "email": { "type": "keyword" },
        "content": { "type": "text" },
        "tweeted_at": { "type": "date" }
      }
    }
  }
}
```

多映射类别数据转储到独立的索引中：

ES 提供了reindex API 来做这个事：

![image-20201117133915850](ES_03 入门/image-20201117133915850.png)

##  字段类型 datatypes

字段类型定义了该如何索引存储字段值。ES中提供了丰富的字段类型定义。

官网链接详细了解每种类型的特点：https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html

### Core Datatypes   核心类型

```shell
string
    text and keyword
Numeric datatypes
    long, integer, short, byte, double, float, half_float, scaled_float
Date datatype
    date
Boolean datatype
    boolean
Binary datatype
    binary
Range datatypes     范围
    integer_range, float_range, long_range, double_range, date_range
```

### Complex datatypes 复合类型

```shell
Array datatype
    数组就是多值，不需要专门的类型
Object datatype
    object ：表示值为一个JSON 对象
Nested datatype
    nested：for arrays of JSON objects（表示值为JSON对象数组 ）
```

### Geo datatypes 地理数据类型

```shell
Geo-point datatype
    geo_point：for lat/lon points  （经纬坐标点）
Geo-Shape datatype
    geo_shape：for complex shapes like polygons （形状表示）
```

### Specialised datatypes 特别的类型

 ```shell
IP datatype
    ip：for IPv4 and IPv6 addresses
Completion datatype
    completion：to provide auto-complete suggestions
Token count datatype
    token_count：to count the number of tokens in a string
mapper-murmur3
    murmur3：to compute hashes of values at index-time and store them in the index
Percolator type
    Accepts queries from the query-dsl
join datatype
    Defines parent/child relation for documents within the same index
 ```

## 字段定义属性介绍

字段的type (Datatype)定义了如何索引存储字段值，还有一些属性可以让我们根据需要来覆盖默认的值或进行特别定义。请参考官网介绍详细了解：

https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-params.htm

```shell
analyzer   指定分词器
normalizer   指定标准化器
boost        指定权重值
coerce      强制类型转换
copy_to    值复制给另一字段
doc_values  是否存储docValues
dynamic
enabled    字段是否可用
fielddata
eager_global_ordinals
format    指定时间值的格式
ignore_above
ignore_malformed
index_options
index
fields
norms
null_value
position_increment_gap
properties
search_analyzer
similarity
store
term_vector
```

### 字段定义属性—示例

```shell
PUT my_index
{
  "mappings": {
    "_doc": {
      "properties": {
        "date": {
          "type":   "date",
           <!--格式化日期 -->
          "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
        }
      }
    }
  }
}
```

## Multi Field 多重字段

当我们需要对一个字段进行多种不同方式的索引时，可以使用fields多重字段定义。如一个字符串字段即需要进行text分词索引，也需要进行keyword 关键字索引来支持排序、聚合；或需要用不同的分词器进行分词索引。

### 实例：定义多重字段：

说明：raw是一个多重版本名（自定义）

```shell
PUT my_index
{
  "mappings": {
    "_doc": {
      "properties": {
        "city": {
          "type": "text",
          "fields": {
            "raw": {
              "type":  "keyword"
            }
          }
        }
      }
    }
  }
}
```

### 往多重字段里面添加文档

```shell
PUT my_index/_doc/1
{
  "city": "New York"
}
PUT my_index/_doc/2
{
  "city": "York"
}
```

### 获取多重字段的值：

```shell
GET my_index/_search
{
  "query": {
    "match": {
      "city": "york"
    }
  },
  "sort": {
    "city.raw": "asc"
  },
  "aggs": {
    "Cities": {
      "terms": {
        "field": "city.raw"
      }
    }
  }
}
```

## 元字段

官网：https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-fields.html

元字段是ES中定义的文档字段，有以下几类：

![image-20201117135049830](ES_03 入门/image-20201117135049830.png)

## **动态映射**

动态映射：ES中提供的重要特性，让我们可以快速使用ES，而不需要先创建索引、定义映射。如我们直接向ES提交文档进行索引：

```shell
PUT data/_doc/1
{ "count": 5 }
```

ES将自动为我们创建data索引、_doc 映射、类型为 long 的字段 count

索引文档时，当有新字段时， ES将根据我们字段的json的数据类型为我们自动加人字段定义到mapping中。

### 字段动态映射规则

![image-20201117135228273](ES_03 入门/image-20201117135228273.png)

### Date detection 时间侦测

所谓时间侦测是指我们往ES里面插入数据的时候会去自动检测我们的数据是不是日期格式的，是的话就会给我们自动转为设置的格式

date_detection 默认是开启的，默认的格式dynamic_date_formats为：

```shell
[ "strict_date_optional_time","yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z"]
PUT my_index/_doc/1
{
  "create_date": "2015/09/02"
}

GET my_index/_mapping
```

#### 自定义时间格式：

```shell
PUT my_index
{
  "mappings": {
    "_doc": {
      "dynamic_date_formats": ["MM/dd/yyyy"]
    }
  }
}
```

#### 禁用时间侦测：

```shell
PUT my_index
{
  "mappings": {
    "_doc": {
      "date_detection": false
    }
  }
}
```

### Numeric detection 数值侦测

开启数值侦测（默认是禁用的）

```shell
PUT my_index
{
  "mappings": {
    "_doc": {
      "numeric_detection": true
    }
  }
}
PUT my_index/_doc/1
{
  "my_float":   "1.0",
  "my_integer": "1"
}
```



# 参考

- https://juejin.im/post/6895585954921185294
- https://juejin.im/post/6894236398136590350